# 가상메모리
: 프로그램이 물리적 메모리를 고려할 필요 없이 자시 자신만이 메모리를 사용하는 것처럼 가정해 프로그램을 지원하는 것. 즉 `가상메모리`는 프로세스마다 각각 0번지부터의 주소 공간을 가지게 되며, 이들 공간 중 일부는 물리적 메모리에 적재되고 일부는 디스크의 스왑 영역에 존재하게 된다.

프로세스의 주소 공간을 메모리로 적재하는 단위에 따라 가상메모리 기법은 `요구 페이징` 방식, `요구 세그먼테이션` 방식으로 구현될 수 있다.
#### 요구 페이징
- 대부분의 경우에는 요구 페이징 방식 사용
- 세부적인 구현에서는 요구 페이징 기법만이 사용
#### 요구 세그먼테이션
- 대게 하나의 세그먼트를 여 러 개의 페이지로 나누어 관리하는 페이지드 세그먼테이션 기법을 사용하는 경우

## 1. 요구 페이징(demand paging)
: 프로그램 실행 시 당장 사용될 페이지만을 올리는 방식
- 메모리 사용량이 감소하고, 프로레스 전체를 메모리에 올리는 데 소요되는 입출력 오버헤드도 줄어든다.
- 응답시간을 단축시킬 수 있으며, 시스템이 더 많은 프로세스를 수용할 수 있게 해준다.
- 프로그램을 구성하는 페이지 중 일부만을 메모리에 적재하게 되므로 물리적 메모리의 용량보다 큰 프로그램도 실행할 수 있다.
### Valid/Invalid bit 사용
프로세스가 실행되기 전에는 모든 페이지는 invalid으로 초기화 되어 있다.
#### Valid bit
- 특정 페이지가 참조되어 메모리에 적재되는 경우
#### Invalid bit
- 페이지가 현재 메모리에 없는 경우
- 그 페이지가 속한 주소 영역을 프로세스가 사용하지 않는 경우
![페이지 테이블에서 유효 무효 비트의 의미](https://velog.velcdn.com/images/zzallang/post/f027f420-75d3-4295-aa04-48c4e25438d9/image.jpg)


#### page fault
: address translation 시에 invalid bit가 set 되어 있는 것
  => CPU가 참조하려는 페이지가 현재 미모리에 올라와있지 않아 무효 비트가 무효로 세팅되어 있는 경우
  - page fault 발생 시 CPU는 자동적으로 운영체제에게 넘어가게 된다. 
  - `page trap`이 걸렸다고도 하며 일종의 소프트웨어의 인터럽트

### 1) Page fault 
- CPU가 invalid page에 접근하면 MMU가 page fault trap을 발생시키게 된다.
- Kernel mode로 전한이 되고 `page fault hander`가 invoke 된다.
  - page fault handler : page fault를 처리하는 코드
#### page fault 처리 루틴
1. 해당 페이지에 대한 접근이 적법한지 체크한다.
- 잘못된 주소, 접근 권한 위반(protection violation)
    => abort process (프로세스 종료)
2. 물리적 메모리에서 free frame을 할당받아 그 공간에 페이지를 읽어 온다.
- 만약 empty free frame이라면 기존에 메모리에 올라와 있는 페이지 중 하나를 디스크로 쫓아낸다. (= swap out)
3. 해당 페이지를 디스크에서 메모리로 읽어 온다.
-  Disk I/O가 끝날 때까지 이 프로세스는 CPU를 preempt(빼앗기고) block 상태(봉쇄 상태)가 된다.
- Disk I/O가 끝나면 page tales entry를 기록하고 valid/invalid bit는 valid로 설정한다.
- block 상태였던 프로세스를 ready queue로 이동시킨다.
4. 이 프로세스가 CPU를 할당받고 이전에 중단되었던 instruction부터 실행 재개

![페이지 부재를 처리하는 과정](https://velog.velcdn.com/images/zzallang/post/3ba54a75-b266-4fb4-a1ce-b9183f91241a/image.png)

### 2) 요구 페이징의 기능
: Page fault가 일어나면 디스크로부터 메모리로 읽어오는 막대한 오버헤드가 발생한다. 요구 페이징의 성능은 다음과 같이 `유효 접근시간`으로 측정한다.
- Effective Access Time (유효 접근시간)
= (1 - p) x memory access
	+ p x (OS & HW page fault overhead
    + [swap page out if needed]
    + swap page in
    + OS & HW restrat overhead)
  -  (1 - p) 는 page fault가 안나는 비율이며 안나는 만큼 메모리 접근 시간만 걸리게 된다.
  - OS & HW page fault overhead : 페이지 부재 발생 처리 오버헤드
  - [swap page out if needed] : 메모리에 빈 프레임이 없는 경우 스왑 아웃 오버헤드
  - swap page in : 요청된 페이지의 스왑 인 오버헤드
  - OS & HW restrat overhead : 프로세스의 재시작 오버헤드
  
- Page Fault Rate 0 ≤ p ≤ 1.0 (페이지 부재 발생 비율)
  - if p = 0 on page fault : 0이라면 page fault가 절대 발생되지 않고 메모리에서 다 참조되는 경우
  - if p = 1 : 매번 메모리를 참조할 때마다 page fault가 발생한다.
  
실제로 page fault 비율은 0.0에 가깝게 나오게 되어 대부분의 경우는 page fault가 발생되지 않아 메모리로부터 직접 주소변환을 할 수 있다.
***
## 2. 페이지 교체
#### Page replacement
: Free frame이 없는 경우 메모리에 올라와 있는 페이지 중 하나를 디스크로 쫓아내 메모리에 빈 공간을 확보하는 작업
- 어떤 frame을 빼앗아올지 결정해야 한다.
- 곧바로 사용되지 않을 page를 쫓아내는 것이 좋다
- 동일한 페이지가 여러 번 메모리에서 쫓겨났다가 다시 들어올 수 있다.

![페이지 교체의 예](https://velog.velcdn.com/images/zzallang/post/70fb2637-4172-4c33-8b5f-fe778bd7a3ff/image.png)

#### Replacement Algorithm
: Page replacement시 어떤 frame을 쫓아낼 것인지 결정하는 알고리즘
- page fault rate를 최소화하는 것이 목표
- 알고리즘의 평가
  - 주어진 `page reference stirng`에 대해 page fault를 얼마나 내는지 계산한다.
  - page reference stirng(페이지 참조열) : 시간 순서에 따라서 페이지들에게 서로 다른 순서를 붙여놓고 페이지들의 참조된 순서를 나열해 놓은 것 
  - 해당 번호의 페이지가 이미 올라와 있으면 메모리에서 hit(적중)되었다 하고, 메모리에 없는 경우에는 page fault가 발생했다고 말한다.

### 1) 최적 페이지 교체
#### Optimal Algorithm(MIN,OPT,Belady's Optimal Algorithm)
: page fault rate를 최소화하기 위해 페이지 교체 시 물리적 메모리에 존재하는 페이지 중 가장 먼 미래에 참조될 페이지를 쫓아낼 수 있게 하는 것.

![최적 페이지 교체 알고리즘을 사용한 페이지 교체](https://velog.velcdn.com/images/zzallang/post/ce81afe8-8437-4b66-a2d4-546fa5952b2d/image.png)
- 어떤 알고리즘을 쓰더라도 6 page faults 이하로 할 수 없다.

- 미래의 참조를 어떻게 아는가?
: Offline algoritym
  - 가장 먼 미래에 참조되는 페이지를 미리 다 안다고 **가정**하는 것, 실제 온라인에서 사용할 수는 없다.
- 실제 시스템에서 사용하는 다른 알고리즘의 성능에 대한 upper bound(상한선) 제공
  - 아무리 좋은 알고리즘을 만들어도 Optimal Algorithm보다 좋을 수 없다.
### 2) FIFO(First In First Out : 선입선출) Algorithm
: 페이지 교체 시 물리적 메모릴에 가장 먼저 올라온 페이지를 우선적으로 내쫓는다.
- FIFO anomaly(FIFO의 이상현상) : 메모리를 증가시켰음에도 불구하고 페이지 부재가 오히려 늘어나는 상황
![FIFO 알고리즘에 의한 페이지 교체 1](https://velog.velcdn.com/images/zzallang/post/1d1f0498-2ff7-4faf-a4ad-08228e99c87f/image.png)
![FIFO 알고리즘에 의한 페이지 교체 2](https://velog.velcdn.com/images/zzallang/post/db1fc59d-e7ea-4e39-af29-d27af1765da2/image.png)
### 3) LRU (Least Recently Used) Algorithm
가장 오래 전에 참조된 것을 지운다.
![LRU  알고리즘에 의한 페이지 교체](https://velog.velcdn.com/images/zzallang/post/6d3ea171-4543-49f6-aa6c-53c19e73f292/image.png)
### 4) LFU (Least Frequently Used) Algoritym
: 과거의 regerence count(참조 횟수)가 가장 적은 페이지를 지운다.
- 최저 참조 횟수인 page가 여럿 있는 경우
  - LFU algorithm 자체에서는 여러 page 중 임의로 선정한다.
  - 성능 향상을 위해 가장 오래 전에 참조된 page를 지우게 구현하는 것이 효율적이다.
  
페이지의 참조 횟수를 계산하는 방식에 따라 두 가지로 나뉜다.
- Incache-LFU
: 페이지가 물리적 메모리에 올라온 후부터의 참조 횟수를 카운트 하는 방식
: 페이지가 메모리에서 쫓겨났다가 다시 들어온 경우 참조 횟수는 리셋된다.
- Perfect-LFU
: 메모리에 올라와 있는지의 여부와 상관없이 그 페이지의 과거 총 참조 횟수를 카운트 한다.
#### 장단점
- LRU처럼 직전 참조 시점만 보는 것이 아니라 장기적인 시간 규모를 보기 때문에 page의 인기도를 좀 더 정확히 반영할 수 있다.
- 이전 참조 기록까지 모두 보관하고 있어야 하므로 오버헤드가 상대적으로 더 크다.
- 참조 시점의 최근성을 반영하지 못한다.
- LRU보다 구현이 복잡하다.

![LRU  알고리즘과 LFU 알고리즘의 비교](https://velog.velcdn.com/images/zzallang/post/8d92edc4-865b-43a7-a009-c4e391311c9f/image.png)

### 5) Clock Algoritym
: 하드웨어적인 지원을 통해 이와 같은 알고리즘의 운영 오버헤드를 줄인 방식
- LRU를 approximation(근사)시킨 알고리즘으로 NUR(Not Used Reccently) 또는 NRU(Not Reccently Used) 알고리즘 또는 Second chance 알고리즘으로도 불린다.
- LRU처럼 가장 최근에 참조되지 않은 페이지를 대상으로 선정한다는 점에서 LRU와 유사하지만 교체되는 페이지의 참조 시점이 가장 오래되었다는 것을 보장하지는 못한다.
- Reference bit를 사용해서 교체 대상 페이지를 선정한다.
- Reference bit가 0인 것을 찾을 때까지 포인터를 하나씩 앞으로 이동
- 포인터를 이동하는 중에 reference bit 1은 모두 0으로 바꾼다.
- Reference bit가 0인 것을 찾으면 해당 페이지를 교체한다.
- 한 바퀴 되돌아 와서도(=second chance) 0이면 그때에는 replace 당한다.
- 자주 사용되는 페이지라면 second chance가 올 때 1이다.
![클럭 알고리즘](https://velog.velcdn.com/images/zzallang/post/b841cfa5-ad8a-4976-9c4b-7af0d7707dbe/image.png)

#### Colck algorithm의 개선
- reference bit과 modified bit(dirty bit)를 함께 사용한다.
- reference bit = 1 
: 최근에 참조된 페이지
: modified bit = 0
: 최근에 변경된 페이지 (I/O를 동반하는 페이지)
***
## 3. 페이지 프레임의 할당
: 프로세스가 여러 개가 동시에 수행되는 상황에서 각 프로세스에 얼마만큼의 메모리 공간을 할당할 것인인가?
#### Allocation의 필요성
- 메모리 참조 명령어 수행시 명령어, 데이터 등 여러 페이지를 동시 참조할 수 있다.
  - 명령어 수행을 위해 최소한의 할당되어야 하는 frame의 수가 있다.
- Loop를 구성하는 page들은 한꺼번에 allocate 되는 것이 유리하다.
  - 최소한의 allocation이 없으면 매 loop 마다 fage fault가 발생하게 된다.
### Allocation Scheme
#### Equal Allocation(균등할당)
: 모든 프로세스에게 페이지 프레임을 균일하게 할당하는 방식
#### Proportional Allocaiton(비례할당)
: 프로세스의 크기에 비례해 페이지 프레임을 할당하는 방식
#### Priority Allocation(우선순위 할당)
: 프로세스의 우선순위에 따라 페이지 프레임을 다르게 할당하는 방식
***
## 4. 전역교체와 지역교체
#### Global replacement(전역교체)
: 모든 페이지 프레임이 교체 대상이 될 수 있는 방법
- Replace 시 다른 프로세스에 할당된 프레임을 빼앗아 올 수 있다.
- 프로세스별 할당량을 조절하는 또 다른 방법이 될 수 있다.
- FIFO,LRU,LFU 등의 알고리즘을 global replacement로 사용사에 해당한다.
- Working set, PFF 알고리즘을 사용한다.
#### Local replacement(지역교체)
: 현재 수행 중인 프로세스에세 할당된 프레임 내에서만 교체 대상을 선정할 수 있는 방법
- 자신에게 할당된 프레임 내에서만 선정하기 되는 것이다.
- FIFO,LRU,LFU 등의 알고리즘을 프로세스별로 운영할 때 사용된다.
***
## 5. 스레싱
: 집중적으로 참조되는 페이지들의 집합을 메모리에 한꺼번에 적재하지 못하면 page fault rate가 크게 상승해 CPU utilization이 급격히 떨어지는 현상
- 프로세스의 원활한 수행에 필요한 최소한의 page frame 수를 할당 받지 못한 경우에 발생된다.
- OS는 `MPD`를 높여야 한다고 판단하게 된다.
  - MPD (Multiprograming degree) : 다중 프로그래밍의 정도
- 그러면 또 다른 프로세스가 시스템에 추가된다. (higher MPD)
- 프로세스 당 할당된 프레임의 수가 더욱 감소된다.
- 프로세스는 페이지의 swap in/swap out를 지속적으로 발생시킨다.
- 대부분의 시간은 일을 하지 않게 된다.

=Thrashing
![스레싱 다이어그램 ](https://velog.velcdn.com/images/zzallang/post/7440471d-3e75-4005-becb-cf6902199687/image.JPG)

### 1) Woking-set Algorithm
#### Woking-Set Model
- Locality of reference 
  - 프로세스는 특정 시간동안 일정 장소만을 집중적으로 참조한다.
  - 집중적으로 참조되는 해당 page들의 집합을 `locality set`이라고 한다.
- Woking-set Model
  - Locality에 기반하여 프로세스가 일정 시간 동안 원활하게 수행되기 위해 한꺼번에 메모리에 올라와 있어야 하는 page들의 집합을 `Working Set`이라 정의한다.
  - Working Set 모델에서는 프로세스의 working set 전체가 메모리에 올라와 있어야 수행되고 그렇지 않을 경우 모든 frame을 반납한 후 swap out 시킨다.
  - Thrashing을 방지한다.
  - MPD를 조절한다.
#### Working-set의 결정
- Working-set window를 사용한다
- window size가 Δ인 경우
  - 시각 t₁에서의 working set WS(t₁)
    - Thime interval[t₁-Δ,t₁] 사이에 참조된 서로 다른 페이지들의 집합
  - Working set에 속한 페이지는 메모리에 유지하고 속하지 않은 것은 버린다. (즉, 참조된 후 Δ 시간 동안 해당 페이지를 메모리에 유지한 후 버린다.)
   
![워킹셋 알고리즘의 예](https://velog.velcdn.com/images/zzallang/post/515523e2-415a-44f1-9032-313426c00222/image.png)
#### Working-Set Algorithm
- 프로세스들의 working set size의 합이 page frame의 수보다 큰 경우
  - 일부 프로세스를 swap out 시켜 남은 프로세스들의 working set을 우선적으로 충적시켜 준다. (MPD를 줄임)
-Working set을 다 할당하고도 page frame이 남는 경우
  - swap out 되었던 프로세스에세 working set을 할당 (MPD를 키움)
#### Window size Δ
- Working set을 제대로 탐지하기 위해서는 window size를 잘 결정해야 한다.
- Δ 값이 너무 작으면 locality set을 모두 수용하지 못할 우려가 있다.
- Δ 값이 너무 크면 여러 굼의 locality set을 수용할 수 있다.
- Δ 값이 ∞이면 전체 프로그램을 구성하는 page를 working set으로 간주한다.
### 2) Page Fault Frequency : PFF (페이지 부재 빈도 알고리즘)
#### PFF Scheme
- page fault rate의 upper bound(상한값)과 lower bound(하한값)을 둔다.
  - page fault rate이 upper bound가 넘으면 frame을 더 할당한다.
  - page fault rate이 lower bound가 이하이면 할당 frame 수를 줄인다.
- 빈 frame이 없으면 일부프로세스를 swap out 시켜 프로세스의 수를 조절한다.

![페이지 부재 빈도 알고리즘](https://velog.velcdn.com/images/zzallang/post/15927aae-6186-4485-b683-1f73111c5cfb/image.png)

